{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3\n",
    "Solve efficiently a generic n^2-1 puzzle (also known as Gen Puzzle, Boss Puzzle, Mystic Square) using path-search algorithms\n",
    "- Quality: number of actions in the solution\n",
    "- Cost: the total number of actions evaluated\n",
    "- Efficiency: Quality vs. Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "import numpy as np\n",
    "from heapq import heappop, heappush\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tracemalloc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direction: up, down, left, right\n",
    "# pos1: position of the empty tail\n",
    "# pos2: new possible position\n",
    "action = namedtuple('Action', ['direction','pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_state(state):\n",
    "    \"\"\"Visualize states\"\"\"\n",
    "    for row in state:\n",
    "        print(' '.join(f\"{num:2}\" if num != 0 else \"  \" for num in row))\n",
    "    print()\n",
    "\n",
    "\n",
    "def goal_state(PUZZLE_DIM):\n",
    "    \"\"\" Creates the goal state for an n-puzzle\"\"\"\n",
    "    goal = list(range(1, PUZZLE_DIM * PUZZLE_DIM)) + [0]\n",
    "    return np.array([goal[i * PUZZLE_DIM:(i + 1) * PUZZLE_DIM] for i in range(PUZZLE_DIM)])\n",
    "\n",
    "\n",
    "def precompute_goal_positions(goal_state):\n",
    "    \"\"\"Store the positions of each element according to the goal state\"\"\"\n",
    "    positions = {}\n",
    "    for i in range(goal_state.shape[0]):\n",
    "        for j in range(goal_state.shape[1]):\n",
    "            positions[goal_state[i, j]] = (i, j)\n",
    "    return positions\n",
    "\n",
    "\n",
    "def is_puzzle_solvable(state):\n",
    "    \"\"\"Determines if a given puzzle is solvable.\"\"\"\n",
    "    dim = state.shape[0]  \n",
    "\n",
    "    def get_inv_count(puzzle):\n",
    "        \"\"\"Count inversions in the puzzle.\"\"\"\n",
    "        arr = [tile for row in puzzle for tile in row]\n",
    "        inv_count = 0\n",
    "        for i in range(dim * dim - 1):\n",
    "            for j in range(i + 1, dim * dim):\n",
    "                if arr[j] and arr[i] and arr[i] > arr[j]:\n",
    "                    inv_count += 1\n",
    "        return inv_count\n",
    "\n",
    "    def find_x_position(puzzle):\n",
    "        \"\"\"Find the position of the blank tile (0) from the bottom.\"\"\"\n",
    "        for i in range(dim - 1, -1, -1): \n",
    "            for j in range(dim - 1, -1, -1): \n",
    "                if puzzle[i][j] == 0:\n",
    "                    return dim - i \n",
    "\n",
    "    # Count inversions in the given puzzle\n",
    "    inv_count = get_inv_count(state)\n",
    "\n",
    "    # If grid is odd, \n",
    "    if dim % 2 != 0:\n",
    "        # grid is odd\n",
    "        return inv_count % 2 == 0 #return True if inversion count is even\n",
    "    else:\n",
    "        # grid is even\n",
    "        pos = find_x_position(state)  # 0's position from the bottom\n",
    "        if pos % 2 != 0:  # 0 is on an odd row from the bottom\n",
    "            return inv_count % 2 == 0\n",
    "        else:  # 0 is on an even row from the bottom\n",
    "            return inv_count % 2 != 0\n",
    "        \n",
    "\n",
    "def initialization_puzzle(PUZZLE_DIM, RANDOMIZE_STEPS = 100_000):\n",
    "    state = goal_state(PUZZLE_DIM)\n",
    "    for _ in range(RANDOMIZE_STEPS):\n",
    "        x, y = np.argwhere(state == 0)[0]\n",
    "        state = do_action(state, choice(available_actions(state, (x, y))))\n",
    "    return state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def available_actions(state: np.ndarray, empty_pos) -> list['Action']:\n",
    "    \"\"\"Returns a list of available actions based on the empty tile's position.\"\"\"\n",
    "    # Puzzle dimension\n",
    "    dim = state.shape[0]\n",
    "    # Tile's position \n",
    "    x, y = int(empty_pos[0]), int(empty_pos[1])\n",
    "    \n",
    "    actions = list()\n",
    "   \n",
    "    if x > 0:\n",
    "        # UP\n",
    "        actions.append(action('up', (x, y), (x - 1, y)))\n",
    "    if x < dim - 1:\n",
    "        # DOWN\n",
    "        actions.append(action('down', (x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        # LEFT\n",
    "        actions.append(action('left',(x, y), (x, y - 1)))\n",
    "    if y < dim - 1:\n",
    "        # RIGHT\n",
    "        actions.append(action('right', (x, y), (x, y + 1)))\n",
    "    \n",
    "    return actions\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    \"\"\"Applyes the selected action and returns the new state\"\"\"\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star(start_state, goal_state, verbose=False):\n",
    "    \"\"\"Solves the n-puzzle problem using the A* algorithm\"\"\"\n",
    "\n",
    "    state = start_state\n",
    "\n",
    "    # Counter for tie-breaking in the priority queue\n",
    "    counter = 0\n",
    "    # Total cost (number of evaluated nodes/actions)\n",
    "    evaluated_cost = 0\n",
    "\n",
    "    # Initial empty tile position\n",
    "    x, y = np.argwhere(state == 0)[0] \n",
    "    \n",
    "    # Precompute goal positions for each element of the puzzle\n",
    "    goal_positions = precompute_goal_positions(goal_state)\n",
    "    \n",
    "    # Priority queue for nodes to explore\n",
    "    open_set = []\n",
    "    # Set to store visited nodes\n",
    "    visited = set()\n",
    "    visited.add(state.tobytes())\n",
    "    \n",
    "    # Push the initial state into the priority queue with f = g + h (f = 0 + h)\n",
    "    # (f, counter, current state, path, g)\n",
    "    heappush(open_set, (0 + heuristic(state, goal_positions), counter, state, [(int(x), int(y))], 0))\n",
    "\n",
    "    while open_set:\n",
    "        # Get the state with the lowest f value\n",
    "        f, _, current_state_bytes, path, g = heappop(open_set)\n",
    "\n",
    "        #State in bytes back to a numpy array\n",
    "        current_state = np.frombuffer(current_state_bytes, dtype=int).reshape(state.shape)\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Path: {path}\")\n",
    "            display_state(current_state)\n",
    "            print()\n",
    "\n",
    "        # Check if goal state is reached\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            return path, evaluated_cost\n",
    "\n",
    "        #New tail's position\n",
    "        new_x, new_y = np.argwhere(current_state == 0)[0]\n",
    "        # Available actions\n",
    "        for action in available_actions(current_state, (new_x, new_y)):\n",
    "            new_state = do_action(current_state, action)\n",
    "            new_state_bytes = new_state.tobytes()\n",
    "            \n",
    "            if new_state_bytes not in visited:\n",
    "                visited.add(new_state_bytes)\n",
    "\n",
    "                # Compute heuristic\n",
    "                h = heuristic(new_state, goal_positions)\n",
    "                \n",
    "                # New position and new path after the action\n",
    "                new_pos = action.pos2\n",
    "                new_path = path + [new_pos]\n",
    "                # Push the new state into the priority queue\n",
    "                heappush(open_set, (g + 1 + h, counter, new_state, new_path, g + 1))\n",
    "                \n",
    "                # Increment counter to break ties in case of equal f-values\n",
    "                counter += 1\n",
    "                evaluated_cost += 1\n",
    "\n",
    "    # No solution found\n",
    "    return [], float('inf') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_a_star(start_state, goal_state):\n",
    "    \"\"\"Run A* and measure efficiency metrics.\"\"\"\n",
    "    # Start memory tracking\n",
    "    tracemalloc.start()\n",
    "    # Start time tracking  \n",
    "    start_time = time.perf_counter()  \n",
    "\n",
    "    # Run A* algorithm\n",
    "    path, evaluated_cost = a_star(start_state, goal_state)\n",
    "\n",
    "    end_time = time.perf_counter()  \n",
    "    # Get memory usage\n",
    "    memory_usage, _ = tracemalloc.get_traced_memory()  \n",
    "    tracemalloc.stop()\n",
    "\n",
    "    return path, evaluated_cost, end_time - start_time, memory_usage / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************** Possible Heuristics\n",
    "def hamming_distance(current_state, goal_state):\n",
    "    \"\"\"Compute the Hamming distance between the current state and the goal state.\"\"\"\n",
    "    hamming = 0\n",
    "    puzzle_dim = current_state.shape[0]\n",
    "    for i in range(puzzle_dim):\n",
    "        for j in range(puzzle_dim):\n",
    "            if current_state[i][j] != goal_state[i][j] and current_state[i][j] != 0:\n",
    "                hamming += 1\n",
    "    return hamming\n",
    "\n",
    "\n",
    "def manhattan_distance(state, goal_positions):\n",
    "    \"\"\"Computes the Manhattan distance between the current state and the goal state using pre-calculated goal positions of each element\"\"\"\n",
    "    puzzle_dim = state.shape[0]\n",
    "    distance = 0\n",
    "    for r in range(puzzle_dim):\n",
    "        for c in range(puzzle_dim):\n",
    "            value = state[r, c]\n",
    "            if value != 0:  # Skip the empty tile (element 0)\n",
    "                goal_r, goal_c = goal_positions[value]\n",
    "                distance += abs(goal_r - r) + abs(goal_c - c)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def linear_conflict(state, goal_state):\n",
    "    puzzle_dim = state.shape[0]\n",
    "    conflict_count = 0\n",
    "\n",
    "    # Row conflicts\n",
    "    for row in range(puzzle_dim):\n",
    "        for col1 in range(puzzle_dim):\n",
    "            for col2 in range(col1 + 1, puzzle_dim):\n",
    "                tile1 = state[row, col1]\n",
    "                tile2 = state[row, col2]\n",
    "\n",
    "                # Skip empty tile (0)\n",
    "                if tile1 == 0 or tile2 == 0:\n",
    "                    continue\n",
    "\n",
    "                # Find the positions of the tiles in the goal state\n",
    "                goal_pos1 = np.argwhere(goal_state == tile1)\n",
    "                goal_pos2 = np.argwhere(goal_state == tile2)\n",
    "\n",
    "                # Ensure both tiles are found in the goal state\n",
    "                if goal_pos1.size == 0 or goal_pos2.size == 0:\n",
    "                    continue\n",
    "\n",
    "                goal_pos1 = goal_pos1[0]\n",
    "                goal_pos2 = goal_pos2[0]\n",
    "\n",
    "                # Check if they are in the same row and need to swap places\n",
    "                if goal_pos1[0] == goal_pos2[0] == row and goal_pos1[1] > goal_pos2[1]:\n",
    "                    conflict_count += 2  # Linear conflict adds 2 moves\n",
    "\n",
    "    # Column conflicts\n",
    "    for col in range(puzzle_dim):\n",
    "        for row1 in range(puzzle_dim):\n",
    "            for row2 in range(row1 + 1, puzzle_dim):\n",
    "                tile1 = state[row1, col]\n",
    "                tile2 = state[row2, col]\n",
    "\n",
    "                # Skip empty tile (0)\n",
    "                if tile1 == 0 or tile2 == 0:\n",
    "                    continue\n",
    "\n",
    "                # Find the positions of the tiles in the goal state\n",
    "                goal_pos1 = np.argwhere(goal_state == tile1)\n",
    "                goal_pos2 = np.argwhere(goal_state == tile2)\n",
    "\n",
    "                # Ensure both tiles are found in the goal state\n",
    "                if goal_pos1.size == 0 or goal_pos2.size == 0:\n",
    "                    continue\n",
    "\n",
    "                goal_pos1 = goal_pos1[0]\n",
    "                goal_pos2 = goal_pos2[0]\n",
    "\n",
    "                # Check if they are in the same column and need to swap places\n",
    "                if goal_pos1[1] == goal_pos2[1] == col and goal_pos1[0] > goal_pos2[0]:\n",
    "                    conflict_count += 2  # Linear conflict adds 2 moves\n",
    "\n",
    "    return conflict_count\n",
    "\n",
    "\n",
    "# Combine Manhattan distance with linear conflict\n",
    "def combined_heuristic(state, goal):\n",
    "    return manhattan_distance(state, goal) + 2 * linear_conflict(state, goal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manhattan_distance vs. combined_heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I aim to compare the performance of using manhattan_distance versus combined_heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      " 5  4   \n",
      " 8  1  6\n",
      " 3  7  2\n",
      "\n",
      "Goal state:\n",
      " 1  2  3\n",
      " 4  5  6\n",
      " 7  8   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "PUZZLE_DIM = 3\n",
    "state = initialization_puzzle(PUZZLE_DIM, 100_000)\n",
    "print(\"Initial state:\")\n",
    "display_state(state)\n",
    "# Goal of the puzzle\n",
    "goal = goal_state(PUZZLE_DIM)\n",
    "print(\"Goal state:\")\n",
    "display_state(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic used: Manhattan distance\n",
      "Solving time: 0.22 seconds\n",
      "Memory usage: 0.26\n",
      "\n",
      "Heuristic used: combined heuristics\n",
      "Solving time: 3.00 seconds\n",
      "Memory usage: 0.110036\n"
     ]
    }
   ],
   "source": [
    "heuristic = manhattan_distance\n",
    "_ , _ , solving_time, memory_usage = measure_a_star(state, goal)\n",
    "print(f\"Heuristic used: Manhattan distance\")\n",
    "print(f\"Solving time: {solving_time:.2f} seconds\")\n",
    "print(f\"Memory usage: {memory_usage:.2f}\")\n",
    "print()\n",
    "\n",
    "heuristic = combined_heuristic\n",
    "_ , _ , solving_time, memory_usage = measure_a_star(state, goal)\n",
    "print(f\"Heuristic used: combined heuristics\")\n",
    "print(f\"Solving time: {solving_time:.2f} seconds\")\n",
    "print(f\"Memory usage: {memory_usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, it appears that using the Manhattan Distance heuristic provides significantly faster execution time compared to the Combined Heuristics, though at the cost of higher memory usage.\n",
    "For the upcoming tests, which will focus on solving puzzles of larger dimensions, I will prioritize the Manhattan Distance heuristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIMs = [3, 4, 5, 6]\n",
    "NUM_RAND_STEPS = [100_000, 1_000, 100, 100]\n",
    "heuristic = manhattan_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a 8-puzzle\n",
      "-------------------\n",
      "Initial state:\n",
      " 8  2  7\n",
      " 4     3\n",
      " 1  5  6\n",
      "\n",
      "Goal state:\n",
      " 1  2  3\n",
      " 4  5  6\n",
      " 7  8   \n",
      "\n",
      "Path:\n",
      "[(1, 1), (1, 0), (0, 0), (0, 1), (0, 2), (1, 2), (1, 1), (1, 0), (2, 0), (2, 1), (1, 1), (0, 1), (0, 0), (1, 0), (1, 1), (1, 2), (2, 2), (2, 1), (2, 0), (1, 0), (1, 1), (2, 1), (2, 2)]\n",
      "Quality (number of actions in the solution): 23\n",
      "Cost (total number of actions evaluated): 1432\n",
      "Solving time: 0.01 seconds\n",
      "\n",
      "Solving a 15-puzzle\n",
      "-------------------\n",
      "Initial state:\n",
      "14  8 10  9\n",
      "13  3 12  7\n",
      " 2  1  6 11\n",
      " 5  4 15   \n",
      "\n",
      "Goal state:\n",
      " 1  2  3  4\n",
      " 5  6  7  8\n",
      " 9 10 11 12\n",
      "13 14 15   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for PUZZLE_DIM, steps in zip(PUZZLE_DIMs, NUM_RAND_STEPS):\n",
    "    print(f\"Solving a {PUZZLE_DIM*PUZZLE_DIM-1}-puzzle\")\n",
    "    print(\"-------------------\")\n",
    "\n",
    "    # Initial state\n",
    "    state = initialization_puzzle(PUZZLE_DIM, steps)\n",
    "    print(\"Initial state:\")\n",
    "    display_state(state)\n",
    "\n",
    "    # Goal of the puzzle\n",
    "    goal = goal_state(PUZZLE_DIM)\n",
    "    print(\"Goal state:\")\n",
    "    display_state(goal)\n",
    "\n",
    "    # Check solvability\n",
    "    if not is_puzzle_solvable(state):\n",
    "        print(\"Puzzle is not solvable. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    start_time = time.time()\n",
    "    path, cost = a_star(state, goal)\n",
    "    solving_time = time.time() - start_time\n",
    "   \n",
    "    if path:\n",
    "        print(\"Path:\")\n",
    "        print(path)\n",
    "        print(f\"Quality (number of actions in the solution): {len(path)}\")\n",
    "        print(f\"Cost (total number of actions evaluated): {cost}\")\n",
    "    else:\n",
    "        print(\"No solution found.\")\n",
    "\n",
    "    print(f\"Solving time: {solving_time // 60} minutes and {solving_time % 60:.2f} seconds\" if solving_time > 60 else f\"Solving time: {solving_time:.2f} seconds\")\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
